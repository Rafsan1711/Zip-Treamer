## Notebook Name: Chessmate Data Prep.ipynb

---

## 1. Introduction
eta amar  GambitFlow/synapse-edge ei model er dataset 4 vag korar  notebook. 

---

## 2. Code Implementation

### cell 1
```python
# Cell 1: Environment Setup & Master Database Download
# Purpose: Prepare the environment to split the 5.5M+ dataset into 4 shards.

import os
import sqlite3
import shutil
from huggingface_hub import hf_hub_download, HfApi

# ‡ßß. ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶®
HF_ORG = "GambitFlow"
REPO_ID = f"{HF_ORG}/Synapse-Edge-Data"
MASTER_FILENAME = "synapse_training_final.db"

# ‡¶≤‡ßã‡¶ï‡¶æ‡¶≤ ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶°‡¶ø‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡¶ø
WORKING_DIR = "/content/splitting_lab"
os.makedirs(WORKING_DIR, exist_ok=True)

print(f"üöÄ Starting Data Sharding Process for {REPO_ID}...")

# ‡ß®. ‡¶Æ‡ßá‡¶á‡¶® ‡¶°‡ßá‡¶ü‡¶æ‡¶¨‡ßá‡¶∏ ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
try:
    print(f"‚è≥ Downloading Master Database ({MASTER_FILENAME})...")
    master_db_path = hf_hub_download(
        repo_id=REPO_ID,
        filename=MASTER_FILENAME,
        repo_type="dataset",
        local_dir=WORKING_DIR
    )
    print(f"‚úÖ Master DB Ready at: {master_db_path}")
    print(f"‚öñÔ∏è  Size: {os.path.getsize(master_db_path) / (1024**2):.2f} MB")

except Exception as e:
    print(f"‚ùå Error downloading master database: {e}")

# ‡ß©. ‡¶∞‡ßã (Row) ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ
conn = sqlite3.connect(master_db_path)
cursor = conn.cursor()
cursor.execute("SELECT COUNT(*) FROM training_data")
total_rows = cursor.fetchone()[0]
conn.close()

print(f"\nüìä Total Positions in Master DB: {total_rows:,}")
print(f"üéØ Target: 4 shards of ~{total_rows // 4:,} positions each.")
```
Output:

```text
üöÄ Starting Data Sharding Process for GambitFlow/Synapse-Edge-Data...
‚è≥ Downloading Master Database (synapse_training_final.db)...
/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
synapse_training_final.db:‚Äá100%
‚Äá1.12G/1.12G‚Äá[00:10<00:00,‚Äá324MB/s]
‚úÖ Master DB Ready at: /content/splitting_lab/synapse_training_final.db
‚öñÔ∏è  Size: 1071.69 MB

üìä Total Positions in Master DB: 5,551,558
üéØ Target: 4 shards of ~1,387,889 positions each.
```


---


### cell 2
```python
# Cell 2: Precise Data Sharding logic
# Technique: SQL ATTACH & LIMIT/OFFSET for O(1) memory efficiency

import sqlite3
import os
from tqdm import tqdm

def create_shard(shard_id, start_index, limit_count, master_path):
    shard_name = f"synapse_shard_{shard_id}.db"
    shard_path = os.path.join(WORKING_DIR, shard_name)

    # ‡ßß. ‡¶®‡¶§‡ßÅ‡¶® ‡¶∂‡¶æ‡¶∞‡ßç‡¶° ‡¶°‡¶æ‡¶ü‡¶æ‡¶¨‡ßá‡¶∏ ‡¶§‡ßà‡¶∞‡¶ø
    if os.path.exists(shard_path): os.remove(shard_path)
    shard_conn = sqlite3.connect(shard_path)
    shard_cursor = shard_conn.cursor()

    # ‡ß®. ‡¶∏‡ßç‡¶ï‡¶ø‡¶Æ‡¶æ (Schema) ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ - ‡¶Æ‡ßá‡¶á‡¶® ‡¶°‡¶ø‡¶¨‡¶ø ‡¶è‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶π‡ßÅ‡¶¨‡¶π‡ßÅ ‡¶Æ‡¶ø‡¶≤ ‡¶∞‡ßá‡¶ñ‡ßá
    shard_cursor.execute('''
        CREATE TABLE training_data (
            fen TEXT PRIMARY KEY,
            position_stats TEXT,
            best_move TEXT,
            is_tactical INTEGER,
            difficulty TEXT
        )
    ''')

    # ‡ß©. ‡¶∏‡ßç‡¶™‡¶ø‡¶° ‡¶Ö‡¶™‡ßç‡¶ü‡¶ø‡¶Æ‡¶æ‡¶á‡¶ú‡ßá‡¶∂‡¶®
    shard_cursor.execute('PRAGMA synchronous = OFF')
    shard_cursor.execute('PRAGMA journal_mode = MEMORY')

    # ‡ß™. ‡¶Æ‡ßá‡¶á‡¶® ‡¶°‡¶æ‡¶ü‡¶æ‡¶¨‡ßá‡¶∏‡¶ï‡ßá ‡¶è‡¶á ‡¶ï‡¶æ‡¶®‡ßá‡¶ï‡¶∂‡¶®‡ßá ‡¶∏‡¶Ç‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ (ATTACH) ‡¶ï‡¶∞‡¶æ
    shard_cursor.execute(f"ATTACH DATABASE '{master_path}' AS master_db")

    # ‡ß´. ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶∞‡ßá‡¶û‡ßç‡¶ú‡ßá‡¶∞ ‡¶°‡ßá‡¶ü‡¶æ ‡¶ï‡¶™‡¶ø ‡¶ï‡¶∞‡¶æ (The actual splitting)
    print(f"üì¶ Extracting Shard {shard_id}: Positions {start_index:,} to {start_index + limit_count:,}")
    shard_cursor.execute(f'''
        INSERT INTO training_data
        SELECT * FROM master_db.training_data
        LIMIT {limit_count} OFFSET {start_index}
    ''')

    shard_conn.commit()

    # ‡ß¨. ‡¶≠‡ßá‡¶∞‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶®
    shard_cursor.execute("SELECT COUNT(*) FROM training_data")
    count = shard_cursor.fetchone()[0]

    shard_cursor.execute("DETACH DATABASE master_db")
    shard_conn.close()

    return shard_name, count

# --- ‡¶∏‡ßç‡¶≤‡¶æ‡¶á‡¶∏‡¶ø‡¶Ç ‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤‡¶ï‡ßÅ‡¶≤‡ßá‡¶∂‡¶® ---
total_rows = 5551558
rows_per_shard = total_rows // 4  # ‡ßß,‡ß©‡ßÆ‡ß≠,‡ßÆ‡ßÆ‡ßØ ‡¶ü‡¶ø ‡¶ï‡¶∞‡ßá

print(f"üèóÔ∏è  Starting Sharding Engine...")
shards_info = []

for i in range(1, 5):
    start = (i - 1) * rows_per_shard
    # ‡¶∂‡ßá‡¶∑ ‡¶∂‡¶æ‡¶∞‡ßç‡¶°‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ö‡¶¨‡¶∂‡¶ø‡¶∑‡ßç‡¶ü ‡¶∏‡¶¨‡¶ü‡ßÅ‡¶ï‡ßÅ (‡¶¨‡¶æ‡¶ï‡¶ø ‡¶•‡¶æ‡¶ï‡¶æ ‡ß¶.‡ß´ ‡¶¨‡¶æ ‡ßß-‡ß® ‡¶∞‡ßã) ‡¶®‡¶ø‡ßü‡ßá ‡¶®‡¶ø‡¶¨‡ßá
    limit = rows_per_shard if i < 4 else (total_rows - start)

    name, count = create_shard(i, start, limit, master_db_path)
    shards_info.append((name, count))

print("\n" + "="*50)
print("‚úÖ SHARDING COMPLETE!")
print("="*50)
for name, count in shards_info:
    size = os.path.getsize(os.path.join(WORKING_DIR, name)) / (1024**2)
    print(f"üìÑ {name} | Positions: {count:,} | Size: {size:.2f} MB")
```

Output:

```text
üèóÔ∏è  Starting Sharding Engine...
üì¶ Extracting Shard 1: Positions 0 to 1,387,889
üì¶ Extracting Shard 2: Positions 1,387,889 to 2,775,778
üì¶ Extracting Shard 3: Positions 2,775,778 to 4,163,667
üì¶ Extracting Shard 4: Positions 4,163,667 to 5,551,558

==================================================
‚úÖ SHARDING COMPLETE!
==================================================
üìÑ synapse_shard_1.db | Positions: 1,387,889 | Size: 320.71 MB
üìÑ synapse_shard_2.db | Positions: 1,387,889 | Size: 314.58 MB
üìÑ synapse_shard_3.db | Positions: 1,387,889 | Size: 186.60 MB
üìÑ synapse_shard_4.db | Positions: 1,387,891 | Size: 186.43 MB
```
---

### cell 3
```python
# Cell 3: Uploading the 4 Data Shards to Hugging Face
# Purpose: Finalizing the distributed dataset for a 4-account training setup.

from huggingface_hub import HfApi
import os
import time

# --- ‡ßß. ‡¶ï‡ßç‡¶∞‡ßá‡¶°‡ßá‡¶®‡¶∂‡¶ø‡ßü‡¶æ‡¶≤‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ---
# ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ Hugging Face 'Write' ‡¶ü‡ßã‡¶ï‡ßá‡¶®‡¶ü‡¶ø ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶¨‡¶∏‡¶æ‡¶®
HF_TOKEN = "HF_TOKEN"

HF_ORG = "GambitFlow"
REPO_ID = f"{HF_ORG}/Synapse-Edge-Data"

# ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶≤‡ßã‡¶ï‡¶æ‡¶≤ ‡¶°‡¶ø‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡¶ø ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶∂‡¶æ‡¶∞‡ßç‡¶°‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶õ‡ßá
WORKING_DIR = "/content/splitting_lab"

api = HfApi(token=HF_TOKEN)

print(f"üöÄ Initializing Bulk Upload to: {REPO_ID}")

# ‡ß™‡¶ü‡¶ø ‡¶∂‡¶æ‡¶∞‡ßç‡¶°‡ßá‡¶∞ ‡¶§‡¶æ‡¶≤‡¶ø‡¶ï‡¶æ
shards = [
    "synapse_shard_1.db",
    "synapse_shard_2.db",
    "synapse_shard_3.db",
    "synapse_shard_4.db"
]

def upload_all_shards():
    for shard_name in shards:
        local_path = os.path.join(WORKING_DIR, shard_name)

        if not os.path.exists(local_path):
            print(f"‚ö†Ô∏è  Warning: {shard_name} not found locally. Skipping...")
            continue

        file_size = os.path.getsize(local_path) / (1024**2)
        print(f"\nüì¶ Preparing: {shard_name} ({file_size:.2f} MB)")

        try:
            # ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° (Direct Stream)
            # ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶´‡¶æ‡¶á‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã 'shards/' ‡¶®‡¶æ‡¶Æ‡¶ï ‡¶è‡¶ï‡¶ü‡¶ø ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞‡ßá‡¶∞ ‡¶≠‡ßá‡¶§‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡¶¨ ‡¶Ø‡¶æ‡¶§‡ßá ‡¶∞‡¶ø‡¶™‡ßã‡¶ú‡¶ø‡¶ü‡¶∞‡¶ø ‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞ ‡¶•‡¶æ‡¶ï‡ßá
            start_time = time.time()
            api.upload_file(
                path_or_fileobj=local_path,
                path_in_repo=f"shards/{shard_name}",
                repo_id=REPO_ID,
                repo_type="dataset"
            )
            end_time = time.time()
            print(f"‚úÖ Uploaded {shard_name} in {end_time - start_time:.2f} seconds.")

        except Exception as e:
            print(f"‚ùå Failed to upload {shard_name}: {e}")

# ‡ß®. ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶∂‡ßÅ‡¶∞‡ßÅ
try:
    # ‡¶∞‡¶ø‡¶™‡ßã‡¶ú‡¶ø‡¶ü‡¶∞‡¶ø ‡¶ö‡ßá‡¶ï (‡¶∏‡ßá‡¶´‡¶ü‡¶ø ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá)
    api.create_repo(repo_id=REPO_ID, repo_type="dataset", exist_ok=True)

    upload_all_shards()

    print("\n" + "="*60)
    print("üéâ MISSION ACCOMPLISHED: ALL SHARDS ARE LIVE!")
    print("="*60)
    print(f"üîó Check Shards Here: https://huggingface.co/datasets/{REPO_ID}/tree/main/shards")
    print("="*60)

except Exception as e:
    print(f"‚ùå Critical Error: {e}")
```

Output:

```text
üöÄ Initializing Bulk Upload to: GambitFlow/Synapse-Edge-Data

üì¶ Preparing: synapse_shard_1.db (320.71 MB)
Processing‚ÄáFiles‚Äá(1‚Äá/‚Äá1)‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá336MB‚Äá/‚Äá‚Äá336MB,‚Äá70.1MB/s‚Äá‚Äá
New‚ÄáData‚ÄáUpload‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá336MB‚Äá/‚Äá‚Äá336MB,‚Äá70.1MB/s‚Äá‚Äá
‚Äá‚Äá...ng_lab/synapse_shard_1.db:‚Äá100%
‚Äá‚Äá336MB‚Äá/‚Äá‚Äá336MB‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá
‚úÖ Uploaded synapse_shard_1.db in 7.65 seconds.

üì¶ Preparing: synapse_shard_2.db (314.58 MB)
Processing‚ÄáFiles‚Äá(1‚Äá/‚Äá1)‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá330MB‚Äá/‚Äá‚Äá330MB,‚Äá56.9MB/s‚Äá‚Äá
New‚ÄáData‚ÄáUpload‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá330MB‚Äá/‚Äá‚Äá330MB,‚Äá56.9MB/s‚Äá‚Äá
‚Äá‚Äá...ng_lab/synapse_shard_2.db:‚Äá100%
‚Äá‚Äá330MB‚Äá/‚Äá‚Äá330MB‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá
‚úÖ Uploaded synapse_shard_2.db in 7.93 seconds.

üì¶ Preparing: synapse_shard_3.db (186.60 MB)
Processing‚ÄáFiles‚Äá(1‚Äá/‚Äá1)‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá196MB‚Äá/‚Äá‚Äá196MB,‚Äá48.9MB/s‚Äá‚Äá
New‚ÄáData‚ÄáUpload‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá196MB‚Äá/‚Äá‚Äá196MB,‚Äá48.9MB/s‚Äá‚Äá
‚Äá‚Äá...ng_lab/synapse_shard_3.db:‚Äá100%
‚Äá‚Äá196MB‚Äá/‚Äá‚Äá196MB‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá
‚úÖ Uploaded synapse_shard_3.db in 6.72 seconds.

üì¶ Preparing: synapse_shard_4.db (186.43 MB)
Processing‚ÄáFiles‚Äá(1‚Äá/‚Äá1)‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá195MB‚Äá/‚Äá‚Äá195MB,‚Äá37.6MB/s‚Äá‚Äá
New‚ÄáData‚ÄáUpload‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá:‚Äá100%
‚Äá‚Äá195MB‚Äá/‚Äá‚Äá195MB,‚Äá37.6MB/s‚Äá‚Äá
‚Äá‚Äá...ng_lab/synapse_shard_4.db:‚Äá100%
‚Äá‚Äá195MB‚Äá/‚Äá‚Äá195MB‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá‚Äá
‚úÖ Uploaded synapse_shard_4.db in 6.99 seconds.

============================================================
üéâ MISSION ACCOMPLISHED: ALL SHARDS ARE LIVE!
============================================================
üîó Check Shards Here: https://huggingface.co/datasets/GambitFlow/Synapse-Edge-Data/tree/main/shards
============================================================
```
---
